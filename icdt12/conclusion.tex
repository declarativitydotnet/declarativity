\section{Conclusion and Future Work}
\label{sec:conclusion}
Much of the traditional discourse in distributed databases and distributed systems focuses on the construction and verification of specific protocols for ensuring desirable properties.  It is typical in that work to achieve general results by using minimalist models of program behavior: typically, traces of opaque reads, writes, and messages.  By starting with logic programming, our work has led us to a somewhat different angle of attack: the analysis of whole programs for desirable distributed properties.  Building on the literature of non-montonic logic, we can make good use of simple syntactic tests like the presence of negation, and also reason about richer semantic tests for monotonic properties that can hold despite non-monotonic syntax.  This approach can lead to more nuanced tests than traditional models, since it takes into account not only what a program may do \emph{to} data and in what order, but what the program may do \emph{with} that data in its downstream logic.  As we saw, conservative tests on program logic can sometimes entirely remove the need to worry about the ordering of what the program does to the data.  In other cases, our approach can guide the programmer to parsimonious use of protocols like coordination and replication in their code.  In addition to the foundations presented here, we have begun realizing these analyses and constructions in practical software development tools~\cite{cidr11}.

Given these results, we are encouraged to consider other important properties of distributed systems.  One classical property to investigate is the need for causality of message orderings, as described by Lamport~\cite{timeclocks}.  Our arguments about confluence of monotonic logic in this paper seem to reinforce the conjecture that confluence would hold even with non-causal message orders~\cite{declarative-imperative}.  
%%Another issue to revisit in our formalism is liveness: the property that a system will always eventually achieve desired goal.  

Many other properties of interest only make sense if we extend our model to differentiate separate ``tasks'' or ``transactions''. We believe this can be done mechanistically by introducing some bookkeeping logic into each \lang program.  Given such a framework, one traditional issue to consider analyzing is fairness: the property that each independent task will get an appropriate number of opportunities to evaluate its logic.  Another is to recast the read/write reasoning behind serializability and linearizability in terms of our formalism, and see if we can identify opportunities to relax the need for concurrency control in certain programs.  One interesting conjecture here is that standard lock-free data structures~\cite{lockfree} have inherent monotonicities in their protocols, which would be automatically identifiable in \lang specifications.
